#stuff
import datetime
from sklearn import preprocessing
import matplotlib.pyplot as plt
import seaborn as sns

# for data handling
import pandas as pd
import numpy as np

# train-test split
from sklearn.model_selection import train_test_split

# loss functions for today
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

# stuff for evaluating classifiers
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt # for displaying a pretty confusion matrix

# dummy models for comparison
from sklearn.dummy import DummyClassifier

# classification models
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score

pip install tabulate

import tabulate

bankdf=pd.read_csv("bank-additional-full.csv", sep=';')

bankdf.head()

# CREATION OF YEAR VARIABLE

nemployed = bankdf['nr.employed']

unique, index = np.unique(nemployed, return_index=True) # [5191. , 5228.1, 5195.8, 5176.3, 5099.1, 5076.2, 5017.5, 5023.5, 5008.7, 4991.6, 4963.6]

# 2008: 5191. , 5228.1, 5195.8
# 2009: 5176.3, 5099.1, 5076.2, 5017.5
# 2010: 5023.5, 5008.7, 4991.6, 4963.6

year_df = {'year':['2008','2008','2008','2009','2009','2009','2009','2010','2010','2010','2010'], 
           'nr.employed':[5191. , 5228.1, 5195.8, 5176.3, 5099.1, 5076.2, 5017.5, 5023.5, 5008.7, 4991.6, 4963.6]}
year_df = pd.DataFrame.from_dict(year_df)

bankdf = bankdf.merge(year_df, on='nr.employed', how='left')

# Creating a function to convert the month abbrevuation in number

bankdf["month_name"] = bankdf["month"]

def convert_month(df):
    df['month'] = [int(datetime.datetime.strptime(obv, '%b').month) for obv in df['month_name']]
    df['year'] = [int(obv) for obv in df['year']]
convert_month(bankdf)

## Preprocessing

bankdf["day"] = int(1)
bankdf['date']=pd.to_datetime(bankdf[['year','month','day']])

# Unknown count

#bankdf.nunique()
#bankdf.isnull().sum() # no NAs but there are some classes "Unknown", what should we do with them?

for column in bankdf.select_dtypes(include=object):
     print("\n" + column)
     print(bankdf[column].value_counts().to_markdown())
    
# job: 330 
# marital: 80
# education: 1731
# default: 8597
# housing 990
# loan: 990

bankdf = bankdf.drop_duplicates()
len(bankdf)

bankdf.isnull().sum()

#New Dataframe without unknown values
bankdfn = bankdf[(bankdf['default'] != "unknown") & (bankdf['job'] != "unknown") & (bankdf['marital'] != "unknown") & (bankdf['education'] != "unknown") & (bankdf['housing'] != "unknown") & (bankdf['loan'] != "unknown")]

len(bankdfn)

# If y is yes, then 1 otherwise 0
bankdf['y'] = np.where(bankdf['y']=='yes', 1, 0)

# If y is yes, then 1 otherwise 0
bankdfn['y'] = np.where(bankdfn['y']=='yes', 1, 0)

# Create Dummy Variables

bank_dummies = pd.get_dummies(bankdfn.drop(['month_name', 'date', 'day', 'year'], axis=1), drop_first = True)
bank_dummies.columns 

# dropping year because correlation is too high with the and social features (was created starting from those)


## Classification 

# Standardize X? Why?

# Dataset split into test, validation and training set: 20% or 30 test set? Need validation if use CV?

X = bank_dummies.drop('y', axis=1)
y = bank_dummies["y"]

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) # train and test
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42) # train and validation

print("Xtrain", X_train.shape, "y_train", 
      y_train.shape, "X_test","X_val", X_val.shape, "y_val", 
      y_val.shape, "X_test", X_test.shape, "y_test", y_test.shape) 

# L2
logr = LogisticRegression(max_iter=100000).fit(X_train,y_train)

print("Accuracy on training set: {:.3f}".format(logr.score(X_train,y_train))) #  0.9108606557377049
print("Accuracy on validation set: {:.3f}".format(logr.score(X_val,y_val))) # 0.9131754705525197
print("Accuracy on test set: {:.3f}".format(logr.score(X_test, y_test)))

#print coefficient
coefficient = logr.coef_
coefficient

# Alida copy: Interpretation of C in Logistic Regression

# Tuning alpha/lambda for Ridge

# CAN DO THE SAME WITH LASSO PENALTY

# define grid
alpha_grid = {
    'C':  np.arange(0.1, 1.1, 0.1)
}

# Set up GridSearchCV 
grid_search = GridSearchCV(logr, alpha_grid, cv=10, n_jobs=-1)
alpha_grid

## DOESNT FINISH

# Fit the grid search 
grid_search.fit(X_train, y_train)

# Retrieve and print the scores for each iteration
cv_results = grid_search.cv_results_
for mean_score, params in zip(cv_results["mean_test_score"], cv_results["params"]):
    print(f"Accuracy score for {params}: {mean_score}")

# Retrieve the best hyperparameters and the corresponding best estimator
best_alpha = grid_search.best_params_['C']
best_ridge_model = grid_search.best_estimator_

# Print the best hyperparameters
print(f"Best Alpha for regularization: {best_alpha}")

# Evaluate the best model on the test data
print(f"Validation Accuracy with best model: {best_model.score(X_val, y_val)}")

coefficient = best_model.coef_
coefficient

# L1
logr2 = LogisticRegression(penalty = "l1", solver = "saga", max_iter=100000).fit(X_train,y_train)

print("Accuracy on training set: {:.3f}".format(logr2.score(X_train,y_train))) #  0.9108606557377049
print("Accuracy on validation set: {:.3f}".format(logr2.score(X_val,y_val))) # 0.9131754705525197
print("Accuracy on test set: {:.3f}".format(logr2.score(X_test, y_test)))

# copy Alida
grid_search = GridSearchCV(logr2, alpha_grid, cv=10, n_jobs=-1)

grid_search.fit(X_train, y_train)

# Retrieve and print the scores for each iteration
cv_results = grid_search.cv_results_
for mean_score, params in zip(cv_results["mean_test_score"], cv_results["params"]):
    print(f"Accuracy score for {params}: {mean_score}")

# Retrieve the best hyperparameters and the corresponding best estimator
best_alpha = grid_search.best_params_['C']
best_lasso_model = grid_search.best_estimator_

# Print the best hyperparameters
print(f"Best Alpha for regularization: {best_alpha}")

# Evaluate the best model on the test data
print(f"Validation Accuracy with best model: {best_model.score(X_val, y_val)}")

coefficient = best_model.coef_
coefficient 

# with 0.7 just 1 to 0 - BEST
# with 0.2 a lot to 0

# What's the column to 0?  'education_basic.9y'.... doesn't make sense, would be better to perform a group lasso

# Try with Cross Validation 5 folds

# ATTENTION!!!!! VALIDATION SET HERE DOES NOT MAKE SENSE!!!!

cv5_scores = cross_val_score(model_logit, X_train_standardized, y_train, cv=5)
cv5_scores

print("The average test score is:", cv5_scores.mean())
print("The standard deviation of the test scores is:", cv5_scores.std()) #good!

## KNN

kn = KNeighborsClassifier().fit(X_train,y_train)

kn_y_pred = kn.predict(X_test)

print("Score on training set: {:.3f}".format(kn.score(X_train, y_train)))
print("Score on validation set: {:.3f}".format(kn.score(X_val, y_val)))
print("Score on test set: {:.3f}".format(kn.score(X_test, y_test)))

# The rule of thumb is sqrt(n)
import math 

k = math.ceil(math.sqrt(X_train.shape[0])) # odd number
#163

kn = KNeighborsClassifier(n_neighbors=k)  
kn.fit(X_train,y_train)

print("Score on training set: {:.3f}".format(kn.score(X_train, y_train)))
print("Score on validation set: {:.3f}".format(kn.score(X_val, y_val)))
print("Score on test set: {:.3f}".format(kn.score(X_test, y_test)))

## Decision Tree

from sklearn import tree

# doesnt compute 
dtree = tree.DecisionTreeClassifier(max_depth=3).fit(X_train, y_train)
print("Score on training set: {:.3f}".format(dtree.score(X_train, y_test)))
print("Score on validation set: {:.3f}".format(dtree.score(X_val, y_val)))
print("Score on test set: {:.3f}".format(dtree.score(X_test, y_test)))

## Random Forest

# implement a random forest classifier here
rf = RandomForestClassifier(max_depth=10)
rf.fit(X_train, y_train)
rf_y_pred = rf.predict(X_test)
print("Accuracy on training set: {:.3f}".format(rf.score(X_train, y_train)))
print("Accuracy on validation set: {:.3f}".format(rf.score(X_val, y_val)))
print("Accuracy on test set: {:.3f}".format(rf.score(X_test, y_test)))

# print the random forest classification report here
print(classification_report(y_test, rf_y_pred))

## Confusion Matrix

dm = DummyClassifier()
dm.fit(X_train, y_train)
dm_y_pred = dm.predict(X_test)

print("Accuracy on training set: {:.3f}".format(dm.score(X_train, y_train)))
print("Accuracy on test set: {:.3f}".format(dm.score(X_test, y_test)))

cm = confusion_matrix(y_test, dm_y_pred)
print(cm)

disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                               display_labels=dm.classes_)
disp.plot()
plt.show()

## Fairness

from sklearn.metrics import classification_report, roc_curve, auc

# for fairness assessment
from fairlearn.metrics import MetricFrame, true_positive_rate, false_positive_rate, selection_rate, equalized_odds_difference, demographic_parity_difference, selection_rate

# for mitigation
from fairlearn.postprocessing import ThresholdOptimizer, plot_threshold_optimizer

# Step 1: Compute the predicted probabilities for the positive class
y_prob = rf.predict_proba(X_test)[:,1]

# Step 2: Compute FPR, TPR, and thresholds
fpr, tpr, thresholds = roc_curve(y_test, y_prob)

# Step 3: Compute the AUC
roc_auc = auc(fpr, tpr)

# Step 4: Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--') # diagonal line
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

# extract feature importances
importances = rf.feature_importances_

# pair each feature with its importance
features = X_test.columns 
feature_importance = sorted(zip(importances, features), reverse=True)

# extracting sorted importance values and their corresponding labels for plotting
sorted_importances = [value[0] for value in feature_importance]
sorted_features = [value[1] for value in feature_importance]

# plot the features and their importance
plt.figure(figsize=(10, len(sorted_features) * 0.4)) # adjusting the figure height based on number of features
plt.barh(sorted_features, sorted_importances)
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importance from RandomForest')
plt.gca().invert_yaxis() # to display the feature with the highest importance at the top
plt.show()

# create a MetricFrame to compute metrics across groups
metrics = MetricFrame(metrics={
    'selection_rate': selection_rate,
    'TPR': true_positive_rate, 
    'FPR': false_positive_rate},
    y_true=y_test,y_pred=rf_y_pred,
    sensitive_features=X_test['age'])

# Print the results
print(metrics.by_group)

# Compute the demographic parity difference
dpd = demographic_parity_difference(y_test, rf_y_pred, sensitive_features=X_test["age"])
print(f"Demographic Parity Difference: {dpd:.2f}")

# Compute the equalized odds difference
eod = equalized_odds_difference(y_test, rf_y_pred, sensitive_features=X_test["age"])
print(f"Equalized Odds Difference: {eod:.2f}")

# Instantiate the equalized odds post-processor
postprocessor = ThresholdOptimizer(
    estimator=rf,
    constraints="equalized_odds",
    predict_method='auto',
    prefit=True
)

# Fit the post-processor
postprocessor.fit(X_test, y_test, sensitive_features=X_test['age'])

# Predict using the mitigated model
y_pred_mitigated = postprocessor.predict(X_test, sensitive_features=X_test['age'])
